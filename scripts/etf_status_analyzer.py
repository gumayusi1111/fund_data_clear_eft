#!/usr/bin/env python3
"""
ETFçŠ¶æ€åˆ†æè„šæœ¬
åˆ†ææ—¥æ›´å’Œå‘¨æ›´æ•°æ®å·®å¼‚ï¼Œè¯†åˆ«å¯èƒ½çš„ä¸‹å¸‚å’Œæ–°ä¸Šå¸‚ETF
"""

import os
import sys
import json
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
script_dir = Path(__file__).parent
project_root = script_dir.parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨å’Œæ—¥å¿—é…ç½®
from config.etf_lifecycle_manager import ETFLifecycleManager
from config.logger_config import setup_system_logger, get_report_paths

# é…ç½®è·¯å¾„ - ä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•
DAILY_DIR = project_root / "ETFæ—¥æ›´"
WEEKLY_DIR = project_root / "ETFå‘¨æ›´"
CATEGORIES = ["0_ETFæ—¥K(å‰å¤æƒ)", "0_ETFæ—¥K(åå¤æƒ)", "0_ETFæ—¥K(é™¤æƒ)"]

def get_etf_codes_from_dir(directory: Path, category: str, include_delisted: bool = False) -> set:
    """è·å–æŒ‡å®šç›®å½•å’Œç±»åˆ«ä¸‹çš„æ‰€æœ‰ETFä»£ç """
    category_path = directory / category
    if not category_path.exists():
        return set()
    
    codes = set()
    for filepath in category_path.glob('*.csv'):
        filename = filepath.name
        code = filename.replace('.csv', '')
        # ç»Ÿä¸€å¤„ç†ï¼šç§»é™¤äº¤æ˜“æ‰€åç¼€ï¼ˆå¦‚.SZ, .SHï¼‰
        if '.' in code:
            code = code.split('.')[0]
        codes.add(code)
    
    # å¦‚æœä¸åŒ…å«é€€å¸‚ETFï¼Œåˆ™è¿‡æ»¤æ‰é€€å¸‚çš„
    if not include_delisted:
        # è·å–ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨å®ä¾‹
        lifecycle_manager = ETFLifecycleManager()
        delisted_codes = {etf["code"] for etf in lifecycle_manager.get_delisted_etfs()}
        codes = codes - delisted_codes
    
    return codes

def analyze_etf_differences(daily_codes: set, weekly_codes: set, lifecycle_manager: ETFLifecycleManager) -> dict:
    """åˆ†æETFå·®å¼‚"""
    # è·å–å·²çŸ¥çš„ç”Ÿå‘½å‘¨æœŸä¿¡æ¯
    newly_listed_codes = {etf["code"] for etf in lifecycle_manager.get_newly_listed_etfs()}
    delisted_codes = {etf["code"] for etf in lifecycle_manager.get_delisted_etfs()}
    
    # åªåœ¨æ—¥æ›´ä¸­çš„ä»£ç ï¼ˆå¯èƒ½æ˜¯æ–°ä¸Šå¸‚ï¼‰
    only_in_daily = daily_codes - weekly_codes
    # åªåœ¨å‘¨æ›´ä¸­çš„ä»£ç ï¼ˆå¯èƒ½å·²ä¸‹å¸‚ï¼‰
    only_in_weekly = weekly_codes - daily_codes
    
    return {
        "total_daily": len(daily_codes),
        "total_weekly": len(weekly_codes),
        "common_codes": len(daily_codes & weekly_codes),
        "difference": len(daily_codes) - len(weekly_codes),
        "only_in_daily": {
            "codes": only_in_daily,
            "count": len(only_in_daily),
            "known_new_listed": only_in_daily & newly_listed_codes,
            "unknown_new": only_in_daily - newly_listed_codes
        },
        "only_in_weekly": {
            "codes": only_in_weekly,
            "count": len(only_in_weekly),
            "known_delisted": only_in_weekly & delisted_codes,
            "unknown_missing": only_in_weekly - delisted_codes
        },
        "lifecycle_status": {
            "total_delisted": len(delisted_codes),
            "total_newly_listed": len(newly_listed_codes),
            "delisted_codes": delisted_codes,
            "newly_listed_codes": newly_listed_codes
        }
    }

def analyze_etf_status(include_delisted: bool = False):
    """åˆ†æETFçŠ¶æ€"""
    logger = setup_system_logger()
    logger.info("ğŸ” å¼€å§‹åˆ†æETFçŠ¶æ€...")
    
    if include_delisted:
        logger.info("ğŸ“‹ åŒ…å«é€€å¸‚ETFçš„å®Œæ•´åˆ†æ")
    else:
        logger.info("ğŸ“‹ ä»…åˆ†ææ´»è·ƒETFï¼ˆé»˜è®¤æ¨¡å¼ï¼‰")
    
    # åˆå§‹åŒ–ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨
    lifecycle_manager = ETFLifecycleManager()
    
    # è·å–å„ç±»åˆ«çš„ETFä»£ç 
    daily_codes = set()
    weekly_codes = set()
    
    logger.info("ğŸ“Š æ”¶é›†ETFä»£ç ...")
    for category in CATEGORIES:
        daily_category_codes = get_etf_codes_from_dir(DAILY_DIR, category, include_delisted)
        weekly_category_codes = get_etf_codes_from_dir(WEEKLY_DIR, category, include_delisted)
        
        daily_codes.update(daily_category_codes)
        weekly_codes.update(weekly_category_codes)
        
        logger.info(f"  {category}:")
        logger.info(f"    æ—¥æ›´: {len(daily_category_codes)} ä¸ª")
        logger.info(f"    å‘¨æ›´: {len(weekly_category_codes)} ä¸ª")
    
    # æ˜¾ç¤ºè¿‡æ»¤ä¿¡æ¯
    if not include_delisted:
        delisted_count = len(lifecycle_manager.get_delisted_etfs())
        if delisted_count > 0:
            logger.info(f"ğŸš« å·²è¿‡æ»¤ {delisted_count} ä¸ªé€€å¸‚ETF")
    
    logger.info(f"\nğŸ“‹ æ€»ä½“ç»Ÿè®¡:")
    logger.info(f"  æ—¥æ›´æ€»ETFæ•°: {len(daily_codes)}")
    logger.info(f"  å‘¨æ›´æ€»ETFæ•°: {len(weekly_codes)}")
    logger.info(f"  å…±åŒETFæ•°: {len(daily_codes & weekly_codes)}")
    logger.info(f"  æ•°é‡å·®å¼‚: {len(daily_codes) - len(weekly_codes):+d}")
    
    # åˆ†æå·®å¼‚
    analysis = analyze_etf_differences(daily_codes, weekly_codes, lifecycle_manager)
    
    logger.info(f"\nğŸ”¬ å·®å¼‚åˆ†æ:")
    
    # åªåœ¨æ—¥æ›´ä¸­çš„ETFï¼ˆå¯èƒ½æ˜¯æ–°ä¸Šå¸‚ï¼‰
    if analysis["only_in_daily"]["count"] > 0:
        logger.info(f"ğŸ“ˆ ä»…åœ¨æ—¥æ›´ä¸­çš„ETF: {analysis['only_in_daily']['count']} ä¸ª")
        logger.info(f"    å·²çŸ¥æ–°ä¸Šå¸‚: {len(analysis['only_in_daily']['known_new_listed'])} ä¸ª")
        logger.info(f"    æœªçŸ¥æ–°å¢: {len(analysis['only_in_daily']['unknown_new'])} ä¸ª")
        
        if analysis["only_in_daily"]["unknown_new"]:
            logger.info(f"    ğŸ¤” å¯èƒ½æ˜¯æ–°ä¸Šå¸‚ETF:")
            for code in sorted(analysis["only_in_daily"]["unknown_new"]):
                logger.info(f"       - {code}")
    
    # åªåœ¨å‘¨æ›´ä¸­çš„ETFï¼ˆå¯èƒ½å·²ä¸‹å¸‚ï¼‰
    if analysis["only_in_weekly"]["count"] > 0:
        logger.info(f"ğŸ“‰ ä»…åœ¨å‘¨æ›´ä¸­çš„ETF: {analysis['only_in_weekly']['count']} ä¸ª")
        logger.info(f"    å·²çŸ¥ä¸‹å¸‚: {len(analysis['only_in_weekly']['known_delisted'])} ä¸ª")
        logger.info(f"    æœªçŸ¥ç¼ºå¤±: {len(analysis['only_in_weekly']['unknown_missing'])} ä¸ª")
        
        if analysis["only_in_weekly"]["unknown_missing"]:
            logger.info(f"    ğŸ¤” å¯èƒ½å·²ä¸‹å¸‚çš„ETF:")
            for code in sorted(analysis["only_in_weekly"]["unknown_missing"]):
                logger.info(f"       - {code}")
    
    # æ˜¾ç¤ºå½“å‰ç”Ÿå‘½å‘¨æœŸçŠ¶æ€
    logger.info(f"\nğŸ“Š ç”Ÿå‘½å‘¨æœŸç®¡ç†çŠ¶æ€:")
    newly_listed = lifecycle_manager.get_newly_listed_etfs()
    delisted = lifecycle_manager.get_delisted_etfs()
    
    logger.info(f"æ–°ä¸Šå¸‚ETF: {len(newly_listed)} ä¸ª")
    for etf in newly_listed:
        logger.info(f"  â€¢ {etf['code']} - {etf['name']} (ä¸Šå¸‚: {etf['listing_date']})")
    
    logger.info(f"å·²é€€å¸‚ETF: {len(delisted)} ä¸ª")
    for etf in delisted:
        logger.info(f"  â€¢ {etf['code']} - {etf['name']} (é€€å¸‚: {etf['delisting_date']})")
    
    # æä¾›ç®¡ç†å»ºè®®
    logger.info(f"\nğŸ’¡ ç®¡ç†å»ºè®®:")
    
    if analysis["only_in_daily"]["unknown_new"]:
        logger.info(f"   å»ºè®®æ·»åŠ åˆ°æ–°ä¸Šå¸‚åˆ—è¡¨: {len(analysis['only_in_daily']['unknown_new'])} ä¸ª")
        logger.info(f"   å‘½ä»¤: python scripts/etf_lifecycle_helper.py add-june-2025")
        
    if analysis["only_in_weekly"]["unknown_missing"]:
        logger.info(f"   å»ºè®®æ·»åŠ åˆ°ä¸‹å¸‚åˆ—è¡¨: {len(analysis['only_in_weekly']['unknown_missing'])} ä¸ª")
        logger.info(f"   å‘½ä»¤: python scripts/etf_lifecycle_helper.py add-delisted <ä»£ç > <åç§°> <æ—¥æœŸ>")
    
    if not analysis["only_in_daily"]["unknown_new"] and not analysis["only_in_weekly"]["unknown_missing"]:
        logger.info(f"   âœ… å½“å‰å·®å¼‚éƒ½å·²æœ‰è®°å½•ï¼Œæ— éœ€é¢å¤–ç®¡ç†")
    
    return analysis

def generate_status_report(include_delisted: bool = False):
    """ç”ŸæˆçŠ¶æ€æŠ¥å‘Š"""
    logger = setup_system_logger()
    logger.info("ğŸ“„ ç”ŸæˆETFçŠ¶æ€æŠ¥å‘Š...")
    
    analysis = analyze_etf_status(include_delisted)
    lifecycle_manager = ETFLifecycleManager()
    lifecycle_report, _ = lifecycle_manager.generate_lifecycle_report()
    
    # ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶ï¼ˆè½¬æ¢setä¸ºlistï¼‰
    def convert_sets_to_lists(obj):
        """é€’å½’è½¬æ¢setä¸ºlistä»¥ä¾¿JSONåºåˆ—åŒ–"""
        if isinstance(obj, set):
            return sorted(list(obj))
        elif isinstance(obj, dict):
            return {k: convert_sets_to_lists(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [convert_sets_to_lists(item) for item in obj]
        else:
            return obj
    
    report = {
        "generated_time": datetime.now().isoformat(),
        "etf_analysis": convert_sets_to_lists(analysis),
        "lifecycle_report": lifecycle_report
    }
    
    # ä¿å­˜æŠ¥å‘Šåˆ°çŠ¶æ€æŠ¥å‘Šç›®å½•
    report_paths = get_report_paths()
    status_reports_dir = report_paths['status_reports']
    status_reports_dir.mkdir(parents=True, exist_ok=True)
    
    report_file = status_reports_dir / f"etf_status_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    logger.info(f"ğŸ“„ çŠ¶æ€æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    
    return report

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ETFçŠ¶æ€åˆ†æå™¨')
    parser.add_argument('--include-delisted', action='store_true', 
                       help='åŒ…å«å·²é€€å¸‚ETFè¿›è¡Œåˆ†æ')
    
    args = parser.parse_args()
    
    logger = setup_system_logger()
    logger.info("ğŸš€ ETFçŠ¶æ€åˆ†æå™¨å¯åŠ¨")
    logger.info(f"â° åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not DAILY_DIR.exists():
        logger.error(f"âŒ æ—¥æ›´ç›®å½•ä¸å­˜åœ¨: {DAILY_DIR}")
        return False
    
    if not WEEKLY_DIR.exists():
        logger.error(f"âŒ å‘¨æ›´ç›®å½•ä¸å­˜åœ¨: {WEEKLY_DIR}")
        return False
    
    try:
        # åˆ†æETFçŠ¶æ€
        generate_status_report(args.include_delisted)
        
        logger.info(f"â° å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info("ğŸ‰ ETFçŠ¶æ€åˆ†æå®Œæˆï¼")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {e}")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 