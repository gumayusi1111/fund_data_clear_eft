#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€ETFæ›´æ–°å™¨
ä¸€é”®æ‰§è¡Œæ—¥æ›´å’Œå‘¨æ›´çš„ETFæ•°æ®åŒæ­¥
æ”¯æŒtestæ¨¡å¼éªŒè¯ç³»ç»ŸçŠ¶æ€
"""

import os
import sys
import json
import subprocess
import logging
from datetime import datetime
from pathlib import Path

# è®¾ç½®é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent
sys.path.insert(0, str(PROJECT_ROOT))

# å¯¼å…¥é…ç½®
from config.logger_config import setup_system_logger
from config.hash_manager import HashManager

# å¯¼å…¥æ•°æ®åº“æ¨¡å—
DATABASE_IMPORT_AVAILABLE = False
DailyDataImporter = None
WeeklyDataImporter = None
MarketStatusImporter = None

def load_database_modules():
    """åŠ¨æ€åŠ è½½æ•°æ®åº“å¯¼å…¥æ¨¡å—"""
    global DATABASE_IMPORT_AVAILABLE, DailyDataImporter, WeeklyDataImporter, MarketStatusImporter
    try:
        from ETF_database.importers.daily_importer import DailyDataImporter as _DailyDataImporter
        from ETF_database.importers.weekly_importer import WeeklyDataImporter as _WeeklyDataImporter
        from ETF_database.importers.market_status_importer import MarketStatusImporter as _MarketStatusImporter
        
        DailyDataImporter = _DailyDataImporter
        WeeklyDataImporter = _WeeklyDataImporter
        MarketStatusImporter = _MarketStatusImporter
        DATABASE_IMPORT_AVAILABLE = True
        return True
    except ImportError as e:
        print(f"âš ï¸ æ•°æ®åº“å¯¼å…¥æ¨¡å—ä¸å¯ç”¨: {e}")
        return False

class UnifiedETFUpdater:
    def __init__(self):
        """åˆå§‹åŒ–ç»Ÿä¸€æ›´æ–°å™¨"""
        self.project_root = PROJECT_ROOT
        self.logger = setup_system_logger()
        
        # åŠ è½½é…ç½®
        config_path = self.project_root / "config" / "config.json"
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = json.load(f)
        
        # åˆå§‹åŒ–å“ˆå¸Œç®¡ç†å™¨ - ä½¿ç”¨ç»å¯¹è·¯å¾„
        hash_manager_path = self.project_root / "config" / "hash_manager.py"
        hash_config_path = self.project_root / "config" / "file_hashes.json"
        self.hash_manager = HashManager(str(hash_config_path))
        
        # æ•°æ®åº“å¯¼å…¥é…ç½®
        self.db_config = self.config.get('database_import', {})
        self.auto_import_enabled = self.db_config.get('enabled', True)
        
        # åŠ¨æ€åŠ è½½æ•°æ®åº“æ¨¡å—
        db_loaded = load_database_modules()
        
        self.logger.info("ç»Ÿä¸€ETFæ›´æ–°å™¨åˆå§‹åŒ–å®Œæˆ")
        if db_loaded and self.auto_import_enabled:
            self.logger.info("âœ… æ•°æ®åº“è‡ªåŠ¨å¯¼å…¥å·²å¯ç”¨")
        elif db_loaded and not self.auto_import_enabled:
            self.logger.info("â„¹ï¸ æ•°æ®åº“è‡ªåŠ¨å¯¼å…¥å·²ç¦ç”¨")
        else:
            self.logger.warning("âš ï¸ æ•°æ®åº“å¯¼å…¥æ¨¡å—ä¸å¯ç”¨")
        
    def auto_git_commit(self, success_modules):
        """è‡ªåŠ¨æäº¤Gitæ›´æ–°"""
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨Gitè‡ªåŠ¨æäº¤
        git_config = self.config.get('git_auto_commit', {})
        if not git_config.get('enabled', False):
            self.logger.info("â„¹ï¸ Gitè‡ªåŠ¨æäº¤å·²ç¦ç”¨ï¼Œè·³è¿‡")
            return True
            
        self.logger.info("=" * 50)
        self.logger.info("å¼€å§‹è‡ªåŠ¨Gitæäº¤")
        self.logger.info("=" * 50)
        
        try:
            # æ£€æŸ¥æ˜¯å¦æ˜¯Gitä»“åº“
            result = subprocess.run(
                ["git", "status"],
                cwd=str(self.project_root),
                capture_output=True,
                text=True
            )
            
            if result.returncode != 0:
                self.logger.warning("âš ï¸ å½“å‰ç›®å½•ä¸æ˜¯Gitä»“åº“ï¼Œè·³è¿‡è‡ªåŠ¨æäº¤")
                return False
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å˜æ›´
            result = subprocess.run(
                ["git", "status", "--porcelain"],
                cwd=str(self.project_root),
                capture_output=True,
                text=True
            )
            
            if not result.stdout.strip():
                self.logger.info("â„¹ï¸ æ²¡æœ‰æ–‡ä»¶å˜æ›´ï¼Œè·³è¿‡æäº¤")
                return True
            
            # æ˜¾ç¤ºå˜æ›´çš„æ–‡ä»¶
            self.logger.info("ğŸ“„ æ£€æµ‹åˆ°ä»¥ä¸‹æ–‡ä»¶å˜æ›´:")
            for line in result.stdout.strip().split('\n'):
                if line.strip():
                    self.logger.info(f"   {line}")
            
            # åªæ·»åŠ æ•°æ®æ–‡ä»¶ï¼Œä¸åŒ…å«Pythonè„šæœ¬
            data_patterns = [
                "ETFæ—¥æ›´/0_ETFæ—¥K(å‰å¤æƒ)/*.csv",
                "ETFæ—¥æ›´/0_ETFæ—¥K(åå¤æƒ)/*.csv", 
                "ETFæ—¥æ›´/0_ETFæ—¥K(é™¤æƒ)/*.csv",
                "ETFå‘¨æ›´/0_ETFæ—¥K(å‰å¤æƒ)/*.csv",
                "ETFå‘¨æ›´/0_ETFæ—¥K(åå¤æƒ)/*.csv",
                "ETFå‘¨æ›´/0_ETFæ—¥K(é™¤æƒ)/*.csv",
                "ETFå¸‚åœºçŠ¶å†µ/etf_market_status.json"
            ]
            
            added_files = []
            
            for pattern in data_patterns:
                add_result = subprocess.run(
                    ["git", "add", pattern],
                    cwd=str(self.project_root),
                    capture_output=True,
                    text=True
                )
                
                if add_result.returncode == 0:
                    added_files.append(pattern)
                    self.logger.info(f"âœ… å·²æ·»åŠ æ•°æ®æ–‡ä»¶: {pattern}")
                else:
                    # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨æˆ–æ²¡æœ‰å˜åŒ–ï¼Œä¸æŠ¥é”™
                    if "did not match any files" not in add_result.stderr:
                        self.logger.warning(f"âš ï¸ æ·»åŠ æ–‡ä»¶å¤±è´¥: {pattern} - {add_result.stderr}")
            
            if not added_files:
                self.logger.info("â„¹ï¸ æ²¡æœ‰æ•°æ®æ–‡ä»¶éœ€è¦æäº¤ï¼ˆå¯èƒ½éƒ½æ²¡æœ‰å˜åŒ–ï¼‰")
                return False
            
            # ç”Ÿæˆæäº¤ä¿¡æ¯
            success_count = len([m for m in success_modules.values() if m])
            total_count = len(success_modules)
            
            commit_prefix = git_config.get('commit_message_prefix', 'æ•°æ®è‡ªåŠ¨æ›´æ–°')
            commit_msg = f"{commit_prefix} - æˆåŠŸç‡:{success_count}/{total_count}"
            
            # æ·»åŠ æ—¶é—´æˆ³ï¼ˆå¦‚æœé…ç½®å¯ç”¨ï¼‰
            if git_config.get('include_timestamp', True):
                timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                commit_msg = f"{commit_prefix} {timestamp} - æˆåŠŸç‡:{success_count}/{total_count}"
            
            # æ·»åŠ è¯¦ç»†ä¿¡æ¯
            if success_modules.get('daily'):
                commit_msg += "\nâœ… æ—¥æ›´æ•°æ®å·²æ›´æ–°"
            if success_modules.get('weekly'):
                commit_msg += "\nâœ… å‘¨æ›´æ•°æ®å·²æ›´æ–°"
            if success_modules.get('market_status'):
                commit_msg += "\nâœ… å¸‚åœºçŠ¶å†µå·²æ›´æ–°"
            
            # æ‰§è¡Œæäº¤
            commit_result = subprocess.run(
                ["git", "commit", "-m", commit_msg],
                cwd=str(self.project_root),
                capture_output=True,
                text=True
            )
            
            if commit_result.returncode == 0:
                self.logger.info("âœ… Gitæäº¤æˆåŠŸ")
                self.logger.info(f"ğŸ“ æäº¤ä¿¡æ¯: {commit_msg.split(chr(10))[0]}")
                
                # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦æ¨é€åˆ°è¿œç¨‹ä»“åº“
                if git_config.get('auto_push', True):
                    push_result = subprocess.run(
                        ["git", "push"],
                        cwd=str(self.project_root),
                        capture_output=True,
                        text=True
                    )
                    
                    if push_result.returncode == 0:
                        self.logger.info("âœ… æ¨é€åˆ°è¿œç¨‹ä»“åº“æˆåŠŸ")
                    else:
                        self.logger.warning("âš ï¸ æ¨é€åˆ°è¿œç¨‹ä»“åº“å¤±è´¥ï¼Œä½†æœ¬åœ°æäº¤æˆåŠŸ")
                        self.logger.warning(f"æ¨é€é”™è¯¯: {push_result.stderr}")
                else:
                    self.logger.info("â„¹ï¸ è‡ªåŠ¨æ¨é€å·²ç¦ç”¨ï¼Œä»…æœ¬åœ°æäº¤")
                
                return True
            else:
                self.logger.error(f"âŒ Gitæäº¤å¤±è´¥: {commit_result.stderr}")
                return False
                
        except Exception as e:
            self.logger.error(f"è‡ªåŠ¨Gitæäº¤æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
            return False
    
    def run_database_import(self, import_type: str, base_dir: str = None) -> bool:
        """æ‰§è¡Œæ•°æ®åº“å¯¼å…¥"""
        if not DATABASE_IMPORT_AVAILABLE:
            self.logger.warning("âš ï¸ æ•°æ®åº“å¯¼å…¥æ¨¡å—ä¸å¯ç”¨ï¼Œè·³è¿‡æ•°æ®åº“å¯¼å…¥")
            return False
        
        if not self.auto_import_enabled:
            self.logger.info("â„¹ï¸ æ•°æ®åº“è‡ªåŠ¨å¯¼å…¥å·²ç¦ç”¨ï¼Œè·³è¿‡")
            return True
        
        self.logger.info(f"ğŸ“Š å¼€å§‹æ‰§è¡Œ{import_type}æ•°æ®åº“å¯¼å…¥...")
        
        try:
            if import_type == "daily":
                importer = DailyDataImporter()
                base_dir = base_dir or str(self.project_root / "ETFæ—¥æ›´")
                # åªå¯¼å…¥æœ€è¿‘1å¤©çš„æ•°æ®ï¼ˆå¢é‡å¯¼å…¥ï¼‰
                results = importer.import_latest_data_only(base_dir, days_back=1)
                
            elif import_type == "weekly":
                importer = WeeklyDataImporter()
                base_dir = base_dir or str(self.project_root / "ETFå‘¨æ›´")
                # åªå¯¼å…¥æœ€è¿‘1å‘¨çš„æ•°æ®ï¼ˆå¢é‡å¯¼å…¥ï¼‰
                results = importer.import_latest_weekly_data(base_dir, weeks_back=1)
                
            elif import_type == "market_status":
                importer = MarketStatusImporter()
                json_file = str(self.project_root / "ETFå¸‚åœºçŠ¶å†µ" / "etf_market_status.json")
                results = {"market_status": importer.import_json_file(json_file)}
                
            else:
                self.logger.error(f"âŒ ä¸æ”¯æŒçš„å¯¼å…¥ç±»å‹: {import_type}")
                return False
            
            # æ£€æŸ¥å¯¼å…¥ç»“æœ
            success_count = sum(1 for success in results.values() if success)
            total_count = len(results)
            
            if success_count > 0:
                self.logger.info(f"âœ… {import_type}æ•°æ®åº“å¯¼å…¥å®Œæˆ: {success_count}/{total_count}")
                return True
            else:
                self.logger.warning(f"âš ï¸ {import_type}æ•°æ®åº“å¯¼å…¥æ— æ›´æ–°: {success_count}/{total_count}")
                return False
                
        except Exception as e:
            self.logger.error(f"âŒ {import_type}æ•°æ®åº“å¯¼å…¥å¤±è´¥: {str(e)}")
            return False
        
    def run_daily_update(self):
        """æ‰§è¡Œæ—¥æ›´æµç¨‹ï¼ˆæ™ºèƒ½è·³è¿‡ï¼‰"""
        self.logger.info("=" * 50)
        self.logger.info("å¼€å§‹æ‰§è¡ŒETFæ—¥æ›´æµç¨‹ï¼ˆæ™ºèƒ½æ£€æŸ¥ï¼‰")
        self.logger.info("=" * 50)
        try:
            daily_script = self.project_root / "ETFæ—¥æ›´" / "auto_daily_sync.py"
            if not daily_script.exists():
                self.logger.error(f"æ—¥æ›´è„šæœ¬ä¸å­˜åœ¨: {daily_script}")
                return False, "è„šæœ¬ä¸å­˜åœ¨"
            daily_dir = self.project_root / "ETFæ—¥æ›´"
            cmd = [sys.executable, "auto_daily_sync.py"]
            result = subprocess.run(
                cmd,
                cwd=str(daily_dir),
                capture_output=True,
                text=True,
                encoding='utf-8'
            )
            output = result.stdout + result.stderr
            if "æ²¡æœ‰æ‰¾åˆ°ä»Šå¤©çš„æ–‡ä»¶" in output or "æœªæ‰¾åˆ°ä»»ä½•æ–‡ä»¶" in output:
                self.logger.info("ğŸ“… ä»Šå¤©æ— æ–°æ•°æ®ï¼Œæ™ºèƒ½è·³è¿‡æ—¥æ›´")
                return False, "æ— æ–°æ•°æ®"
            if "æ‰€æœ‰æ–‡ä»¶éƒ½å·²æ˜¯æœ€æ–°" in output or "æ— éœ€ä¸‹è½½" in output:
                self.logger.info("ğŸ“… æ—¥æ›´æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œæ™ºèƒ½è·³è¿‡")
                return False, "å·²æ˜¯æœ€æ–°"
            if result.returncode == 0 and ("å¤„ç†å®Œæˆ" in output or "ä¸‹è½½å®Œæˆ" in output or "åˆå¹¶å®Œæˆ" in output):
                self.logger.info("âœ… ETFæ—¥æ›´å®Œæˆï¼ˆæœ‰æ–°æ•°æ®ï¼‰")
                return True, "æœ‰æ–°æ•°æ®"
            else:
                self.logger.error("âŒ ETFæ—¥æ›´å¤±è´¥")
                if result.stderr:
                    self.logger.error(f"é”™è¯¯: {result.stderr[:200]}...")
                return False, "æ‰§è¡Œå¤±è´¥"
        except Exception as e:
            self.logger.error(f"æ‰§è¡Œæ—¥æ›´æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
            return False, f"å¼‚å¸¸: {str(e)}"

    def run_weekly_update(self):
        """æ‰§è¡Œå‘¨æ›´æµç¨‹ï¼ˆæ™ºèƒ½è·³è¿‡ï¼‰"""
        self.logger.info("=" * 50)
        self.logger.info("å¼€å§‹æ‰§è¡ŒETFå‘¨æ›´æµç¨‹ï¼ˆæ™ºèƒ½æ£€æŸ¥ï¼‰")
        self.logger.info("=" * 50)
        try:
            weekly_script = self.project_root / "ETFå‘¨æ›´" / "etf_auto_sync.py"
            if not weekly_script.exists():
                self.logger.error(f"å‘¨æ›´è„šæœ¬ä¸å­˜åœ¨: {weekly_script}")
                return False, "è„šæœ¬ä¸å­˜åœ¨"
            weekly_dir = self.project_root / "ETFå‘¨æ›´"
            cmd = [sys.executable, "etf_auto_sync.py"]
            result = subprocess.run(
                cmd,
                cwd=str(weekly_dir),
                capture_output=True,
                text=True,
                encoding='utf-8'
            )
            output = result.stdout + result.stderr
            if "æ‰€æœ‰æ–‡ä»¶éƒ½å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€ä¸‹è½½" in output:
                self.logger.info("ğŸ“Š å‘¨æ›´å‹ç¼©åŒ…æ— å˜åŒ–ï¼Œæ™ºèƒ½è·³è¿‡")
                return False, "æ— å˜åŒ–"
            if "æœªæ‰¾åˆ°" in output and "æœˆ" in output:
                self.logger.info("ğŸ“Š æœªæ‰¾åˆ°å½“å‰æœˆä»½å‹ç¼©åŒ…ï¼Œæ™ºèƒ½è·³è¿‡")
                return False, "æ— å½“æœˆæ•°æ®"
            if result.returncode == 0 and ("æ•°æ®åŒæ­¥å®Œæˆ" in output or "åˆå¹¶å®Œæˆ" in output or "ä¸‹è½½å®Œæˆ" in output):
                self.logger.info("âœ… ETFå‘¨æ›´å®Œæˆï¼ˆæœ‰æ–°æ•°æ®ï¼‰")
                return True, "æœ‰æ–°æ•°æ®"
            else:
                self.logger.error("âŒ ETFå‘¨æ›´å¤±è´¥")
                if result.stderr:
                    self.logger.error(f"é”™è¯¯: {result.stderr[:200]}...")
                return False, "æ‰§è¡Œå¤±è´¥"
        except Exception as e:
            self.logger.error(f"æ‰§è¡Œå‘¨æ›´æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
            return False, f"å¼‚å¸¸: {str(e)}"

    def run_market_status_check(self, daily_has_new_data: bool):
        """æ‰§è¡ŒETFå¸‚åœºçŠ¶å†µç›‘æ§ï¼ˆä¾èµ–æ—¥æ›´ï¼‰"""
        self.logger.info("=" * 50)
        self.logger.info("å¼€å§‹æ‰§è¡ŒETFå¸‚åœºçŠ¶å†µç›‘æ§ï¼ˆæ™ºèƒ½æ£€æŸ¥ï¼‰")
        self.logger.info("=" * 50)
        if not daily_has_new_data:
            self.logger.info("ğŸ“Š æ—¥æ›´æ— æ–°æ•°æ®ï¼Œæ™ºèƒ½è·³è¿‡å¸‚åœºçŠ¶å†µæ£€æŸ¥")
            return False, "ä¾èµ–æ—¥æ›´è·³è¿‡"
        try:
            market_script = self.project_root / "ETFå¸‚åœºçŠ¶å†µ" / "market_status_monitor.py"
            if not market_script.exists():
                self.logger.error(f"å¸‚åœºçŠ¶å†µç›‘æ§è„šæœ¬ä¸å­˜åœ¨: {market_script}")
                return False, "è„šæœ¬ä¸å­˜åœ¨"
            market_dir = self.project_root / "ETFå¸‚åœºçŠ¶å†µ"
            cmd = [sys.executable, "market_status_monitor.py"]
            result = subprocess.run(
                cmd,
                cwd=str(market_dir),
                capture_output=True,
                text=True,
                encoding='utf-8'
            )
            output = result.stdout + result.stderr
            if result.returncode == 0 and ("æŠ¥å‘Šå·²æ›´æ–°" in output or "ç›‘æ§å®Œæˆ" in output):
                self.logger.info("âœ… ETFå¸‚åœºçŠ¶å†µç›‘æ§å®Œæˆï¼ˆæœ‰æ–°æ•°æ®ï¼‰")
                return True, "æœ‰æ–°æ•°æ®"
            else:
                self.logger.error("âŒ ETFå¸‚åœºçŠ¶å†µç›‘æ§å¤±è´¥")
                if result.stderr:
                    self.logger.error(f"é”™è¯¯: {result.stderr[:200]}...")
                return False, "æ‰§è¡Œå¤±è´¥"
        except Exception as e:
            self.logger.error(f"æ‰§è¡Œå¸‚åœºçŠ¶å†µç›‘æ§æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
            return False, f"å¼‚å¸¸: {str(e)}"

    def test_system_status(self):
        """æµ‹è¯•ç³»ç»ŸçŠ¶æ€"""
        self.logger.info("ğŸ” å¼€å§‹ç³»ç»ŸçŠ¶æ€æµ‹è¯•")
        
        # æ£€æŸ¥ç›®å½•ç»“æ„
        required_dirs = [
            "ETFæ—¥æ›´",
            "ETFå‘¨æ›´", 
            "ETFå¸‚åœºçŠ¶å†µ",
            "config",
            "logs",
            "scripts"
        ]
        
        for dir_name in required_dirs:
            dir_path = self.project_root / dir_name
            if dir_path.exists():
                self.logger.info(f"âœ… ç›®å½•å­˜åœ¨: {dir_name}")
            else:
                self.logger.error(f"âŒ ç›®å½•ç¼ºå¤±: {dir_name}")
        
        # æ£€æŸ¥å…³é”®æ–‡ä»¶
        required_files = [
            "config/config.json",
            "config/hash_manager.py",
            "ETFæ—¥æ›´/auto_daily_sync.py",
            "ETFå‘¨æ›´/etf_auto_sync.py",
            "ETFå¸‚åœºçŠ¶å†µ/market_status_monitor.py"
        ]
        
        for file_path in required_files:
            full_path = self.project_root / file_path
            if full_path.exists():
                self.logger.info(f"âœ… æ–‡ä»¶å­˜åœ¨: {file_path}")
            else:
                self.logger.error(f"âŒ æ–‡ä»¶ç¼ºå¤±: {file_path}")
        
        # æ£€æŸ¥é…ç½®æ–‡ä»¶
        try:
            self.logger.info(f"âœ… é…ç½®åŠ è½½æˆåŠŸï¼ŒåŒ…å« {len(self.config)} ä¸ªé…ç½®é¡¹")
        except Exception as e:
            self.logger.error(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
        
        # æ£€æŸ¥æ—¥å¿—ç³»ç»Ÿ
        log_file = "etf_sync.log"
        log_path = self.project_root / "logs" / "system" / log_file
        
        if log_path.exists():
            self.logger.info(f"âœ… ç»Ÿä¸€æ—¥å¿—æ–‡ä»¶å­˜åœ¨: {log_file}")
        else:
            self.logger.info(f"â„¹ï¸  ç»Ÿä¸€æ—¥å¿—æ–‡ä»¶å°†è‡ªåŠ¨åˆ›å»º: {log_file}")
        
        self.logger.info("ğŸ” ç³»ç»ŸçŠ¶æ€æµ‹è¯•å®Œæˆ")
    
    def run_full_update(self):
        """æ‰§è¡Œå®Œæ•´æ›´æ–°æµç¨‹ï¼ˆæ™ºèƒ½è·³è¿‡æ— æ–°æ•°æ®çš„æµç¨‹ï¼‰"""
        start_time = datetime.now()
        self.logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œå®Œæ•´ETFæ•°æ®æ›´æ–°æµç¨‹ï¼ˆæ™ºèƒ½è·³è¿‡æ— æ–°æ•°æ®ï¼‰")
        results = {
            'daily': False,
            'weekly': False,
            'market_status': False
        }
        reasons = {}
        # 1. æ‰§è¡Œæ—¥æ›´
        daily_has_new, daily_reason = self.run_daily_update()
        results['daily'] = daily_has_new
        reasons['daily'] = daily_reason
        # 2. æ‰§è¡Œå‘¨æ›´
        weekly_has_new, weekly_reason = self.run_weekly_update()
        results['weekly'] = weekly_has_new
        reasons['weekly'] = weekly_reason
        # 3. å¸‚åœºçŠ¶å†µä¾èµ–æ—¥æ›´
        market_has_new, market_reason = self.run_market_status_check(daily_has_new)
        results['market_status'] = market_has_new
        reasons['market_status'] = market_reason
        # 4. æ•°æ®åº“å¯¼å…¥ï¼ˆåªæœ‰æœ‰æ–°æ•°æ®æ‰å¯¼å…¥ï¼‰
        if daily_has_new:
            self.logger.info("ğŸ“¥ æ—¥æ›´æœ‰æ–°æ•°æ®ï¼Œå¯¼å…¥æ•°æ®åº“...")
            self.run_database_import("daily")
        if weekly_has_new:
            self.logger.info("ğŸ“¥ å‘¨æ›´æœ‰æ–°æ•°æ®ï¼Œå¯¼å…¥æ•°æ®åº“...")
            self.run_database_import("weekly")
        if market_has_new:
            self.logger.info("ğŸ“¥ å¸‚åœºçŠ¶å†µæœ‰æ–°æ•°æ®ï¼Œå¯¼å…¥æ•°æ®åº“...")
            self.run_database_import("market_status")
        # 5. åªæœ‰æœ‰æ–°æ•°æ®æ‰å…è®¸Gitæäº¤
        total_success = sum(results.values())
        if total_success > 0:
            self.logger.info("")
            git_success = self.auto_git_commit(results)
            if git_success:
                self.logger.info("âœ… æ•°æ®æ›´æ–°å’ŒGitæäº¤å…¨éƒ¨å®Œæˆï¼")
            else:
                self.logger.warning("âš ï¸ æ•°æ®æ›´æ–°å®Œæˆï¼Œä½†Gitæäº¤å¤±è´¥")
        else:
            self.logger.info("â„¹ï¸ æ²¡æœ‰æˆåŠŸçš„æ›´æ–°ï¼Œè·³è¿‡Gitæäº¤")
        # æ€»ç»“æŠ¥å‘Š
        end_time = datetime.now()
        duration = end_time - start_time
        self.logger.info("=" * 60)
        self.logger.info("ğŸ“Š ETFæ•°æ®æ›´æ–°å®Œæˆæ€»ç»“")
        self.logger.info("=" * 60)
        self.logger.info(f"å¼€å§‹æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        self.logger.info(f"ç»“æŸæ—¶é—´: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
        self.logger.info(f"æ€»è€—æ—¶: {duration}")
        self.logger.info("")
        self.logger.info("å„æ¨¡å—æ‰§è¡Œç»“æœ:")
        for k in results:
            self.logger.info(f"  {k}: {'âœ… æœ‰æ–°æ•°æ®' if results[k] else 'â­ï¸ è·³è¿‡/æ— æ–°æ•°æ®'} ({reasons[k]})")
        self.logger.info(f"æ•´ä½“æœ‰æ–°æ•°æ®æ¨¡å—æ•°: {total_success}/3")
        return results

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ç»Ÿä¸€ETFæ›´æ–°å™¨')
    parser.add_argument('--mode', choices=['update', 'test'], default='update',
                        help='è¿è¡Œæ¨¡å¼: update(æ•°æ®æ›´æ–°), test(ç³»ç»Ÿæµ‹è¯•)')
    parser.add_argument('--no-git', action='store_true',
                        help='ç¦ç”¨Gitè‡ªåŠ¨æäº¤åŠŸèƒ½')
    parser.add_argument('--no-push', action='store_true',
                        help='ç¦ç”¨Gitè‡ªåŠ¨æ¨é€åŠŸèƒ½ï¼ˆä»…æœ¬åœ°æäº¤ï¼‰')
    
    args = parser.parse_args()
    
    updater = UnifiedETFUpdater()
    
    # æ ¹æ®å‘½ä»¤è¡Œå‚æ•°ä¸´æ—¶ä¿®æ”¹é…ç½®
    if args.no_git:
        updater.config['git_auto_commit']['enabled'] = False
        updater.logger.info("ğŸ”§ å·²é€šè¿‡å‘½ä»¤è¡Œå‚æ•°ç¦ç”¨Gitè‡ªåŠ¨æäº¤")
    
    if args.no_push:
        updater.config['git_auto_commit']['auto_push'] = False
        updater.logger.info("ğŸ”§ å·²é€šè¿‡å‘½ä»¤è¡Œå‚æ•°ç¦ç”¨Gitè‡ªåŠ¨æ¨é€")
    
    if args.mode == 'test':
        # æµ‹è¯•æ¨¡å¼
        updater.test_system_status()
    else:
        # æ­£å¸¸æ›´æ–°æ¨¡å¼
        updater.run_full_update()

if __name__ == "__main__":
    main() 